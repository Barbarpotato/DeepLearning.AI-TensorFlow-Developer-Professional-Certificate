{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem-B3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import shutil\n",
        "import random"
      ],
      "metadata": {
        "id": "i-2ZqWIVHR-w"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = 'https://github.com/dicodingacademy/assets/releases/download/release-rps/rps.zip'\n",
        "urllib.request.urlretrieve(data_url, 'rps.zip')\n",
        "local_file = 'rps.zip'\n",
        "zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "zip_ref.extractall('data/')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "EV6wVyvgZqfH"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_path = '/content/data/rps'\n",
        "\n",
        "source_paper = os.path.join(source_path, 'paper')\n",
        "source_rock = os.path.join(source_path, 'rock')\n",
        "source_scissors = os.path.join(source_path, 'scissors')\n",
        "\n",
        "print(len(os.listdir(source_paper)))\n",
        "print(len(os.listdir(source_rock)))\n",
        "print(len(os.listdir(source_scissors)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqb4k2EDaO5q",
        "outputId": "e0a9e8b9-23a9-45f5-e2dd-71d5bd37a173"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "840\n",
            "840\n",
            "840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/tmp/rock_paper_scissor'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "path_1 = os.path.join(root_dir, \"training\")\n",
        "os.makedirs(path_1)\n",
        "path_2 = os.path.join(root_dir, 'testing')\n",
        "os.makedirs(path_2)\n",
        "\n",
        "path_paper_train = os.path.join(path_1, \"paper\")\n",
        "path_rock_train = os.path.join(path_1, \"rock\")\n",
        "path_scissors_train = os.path.join(path_1, \"scissors\")\n",
        "os.makedirs(path_paper_train)\n",
        "os.makedirs(path_rock_train)\n",
        "os.makedirs(path_scissors_train)\n",
        "\n",
        "path_paper_test = os.path.join(path_2, \"paper\")\n",
        "path_rock_test = os.path.join(path_2, \"rock\")\n",
        "path_scissors_test = os.path.join(path_2, \"scissors\")\n",
        "os.makedirs(path_rock_test)\n",
        "os.makedirs(path_paper_test)\n",
        "os.makedirs(path_scissors_test)"
      ],
      "metadata": {
        "id": "7NrLMhLtbvYN"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: split_data\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "\n",
        "  ### START CODE HERE\n",
        "  list_file = []\n",
        "\n",
        "  for a in os.listdir(SOURCE):\n",
        "    path = os.path.join(SOURCE, a) \n",
        "    get_data = os.path.getsize(path)\n",
        "    if get_data == 0:\n",
        "      print(\"{} is zero length, so ignoring.\".format(a))\n",
        "    else:\n",
        "      list_file.append(a)\n",
        "\n",
        "  # untuk menentukan split size\n",
        "  amount_of_data = int(SPLIT_SIZE * len(list_file))\n",
        "  # Split data tergantung dari argument split size\n",
        "  list_new_file_train = [a for a in list_file[:amount_of_data]]\n",
        "  list_new_file_testing = [a for a in list_file[amount_of_data:]]\n",
        "\n",
        "  #random data inside it\n",
        "  list_new_file_train = random.sample(list_new_file_train, len(list_new_file_train))\n",
        "  list_new_file_testing = random.sample(list_new_file_testing, len(list_new_file_testing))\n",
        "\n",
        "#copying the data for training\n",
        "  for x in list_new_file_train:\n",
        "    path = os.path.join(SOURCE, x) \n",
        "    get_data = os.path.getsize(path)\n",
        "    if get_data == 0:\n",
        "      print(\"{} is zero length, so ignoring.\".format(x))\n",
        "    else:\n",
        "      shutil.copyfile(SOURCE+x , TRAINING+x)\n",
        "\n",
        "#copying the data for testing\n",
        "  for y in list_new_file_testing: \n",
        "    path = os.path.join(SOURCE, y) \n",
        "    get_data = os.path.getsize(path)\n",
        "    if get_data == 0:\n",
        "      print(\"{} is zero length, so ignoring.\".format(x))\n",
        "    else:\n",
        "      shutil.copyfile(SOURCE+y , TESTING+y)\n",
        "  \n",
        "  ### END CODE HERE"
      ],
      "metadata": {
        "id": "KfQTpTgaeDc9"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your split_data function\n",
        "\n",
        "# Define paths\n",
        "ROCK_SOURCE_DIR = \"/content/data/rps/rock/\"\n",
        "PAPER_SOURCE_DIR = \"/content/data/rps/paper/\"\n",
        "SCISSORS_SOURCE_DIR = \"/content/data/rps/scissors/\"\n",
        "\n",
        "TRAINING_DIR = \"/tmp/rock_paper_scissor/training/\"\n",
        "TESTING_DIR = \"/tmp/rock_paper_scissor/testing/\"\n",
        "\n",
        "TRAINING_ROCK_DIR = os.path.join(TRAINING_DIR, \"rock/\")\n",
        "TESTING_ROCK_DIR = os.path.join(TESTING_DIR, \"rock/\")\n",
        "\n",
        "TRAINING_PAPER_DIR = os.path.join(TRAINING_DIR, \"paper/\")\n",
        "TESTING_PAPER_DIR = os.path.join(TESTING_DIR, \"paper/\")\n",
        "\n",
        "TRAINING_SCISSORS_DIR = os.path.join(TRAINING_DIR, \"scissors/\")\n",
        "TESTING_SCISSORS_DIR = os.path.join(TESTING_DIR, \"scissors/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_ROCK_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_ROCK_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_PAPER_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_PAPER_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_SCISSORS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_SCISSORS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_ROCK_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_ROCK_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_PAPER_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_PAPER_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_SCISSORS_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_SCISSORS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .9\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(ROCK_SOURCE_DIR, TRAINING_ROCK_DIR, TESTING_ROCK_DIR, split_size)\n",
        "split_data(PAPER_SOURCE_DIR, TRAINING_PAPER_DIR, TESTING_PAPER_DIR, split_size)\n",
        "split_data(SCISSORS_SOURCE_DIR, TRAINING_SCISSORS_DIR, TESTING_SCISSORS_DIR, split_size)\n",
        "\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_ROCK_DIR))} images of ROCK for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_ROCK_DIR))} images of ROCK for training\")\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_PAPER_DIR))} images of PAPER for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_PAPER_DIR))} images of PAPER for training\")\n",
        "\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_SCISSORS_DIR))} images of SCISSORS for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_SCISSORS_DIR))} images of SCISSORS for training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PAqPTrMiMap",
        "outputId": "aacf068c-278e-4213-aa4e-60611be2090f"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are 756 images of ROCK for training\n",
            "There are 84 images of ROCK for training\n",
            "\n",
            "\n",
            "There are 756 images of PAPER for training\n",
            "There are 84 images of PAPER for training\n",
            "\n",
            "\n",
            "There are 756 images of SCISSORS for training\n",
            "There are 84 images of SCISSORS for training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
        "                                     rotation_range=40,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "# Pass in the appropriate arguments to the flow_from_directory method\n",
        "train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                    batch_size=70,\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "# Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "# Pass in the appropriate arguments to the flow_from_directory method\n",
        "validation_generator = validation_datagen.flow_from_directory(directory=TESTING_DIR,\n",
        "                                                              batch_size=10,\n",
        "                                                              target_size=(150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ74TPTYk_2a",
        "outputId": "7a9896c5-68dc-47ae-d68a-9dbf1a14ee2b"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2268 images belonging to 3 classes.\n",
            "Found 252 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([ \n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']) "
      ],
      "metadata": {
        "id": "MDlnlx9BmcKB"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator,\n",
        "          epochs=15,\n",
        "          validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wdNVLdDnsH8",
        "outputId": "87c65ee0-6e0c-4a0f-9655-e99a20528112"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 62s 2s/step - loss: 6.5472 - accuracy: 0.3708 - val_loss: 0.9458 - val_accuracy: 0.4802\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 62s 2s/step - loss: 1.0137 - accuracy: 0.4784 - val_loss: 0.7488 - val_accuracy: 0.7302\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 61s 2s/step - loss: 0.9207 - accuracy: 0.5847 - val_loss: 0.6550 - val_accuracy: 0.6190\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 61s 2s/step - loss: 0.7984 - accuracy: 0.6711 - val_loss: 0.5032 - val_accuracy: 0.8294\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 61s 2s/step - loss: 0.6766 - accuracy: 0.7447 - val_loss: 0.5212 - val_accuracy: 0.7222\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 62s 2s/step - loss: 0.6318 - accuracy: 0.7478 - val_loss: 0.3972 - val_accuracy: 0.8492\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 60s 2s/step - loss: 0.5765 - accuracy: 0.7941 - val_loss: 0.2852 - val_accuracy: 0.9127\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 61s 2s/step - loss: 0.4519 - accuracy: 0.8197 - val_loss: 0.2040 - val_accuracy: 0.9563\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 62s 2s/step - loss: 0.4489 - accuracy: 0.8479 - val_loss: 0.2113 - val_accuracy: 0.9484\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 60s 2s/step - loss: 0.3664 - accuracy: 0.8699 - val_loss: 0.1555 - val_accuracy: 0.9643\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 60s 2s/step - loss: 0.3106 - accuracy: 0.8884 - val_loss: 0.0925 - val_accuracy: 0.9762\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 62s 2s/step - loss: 0.3270 - accuracy: 0.8862 - val_loss: 0.1165 - val_accuracy: 0.9603\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 60s 2s/step - loss: 0.3391 - accuracy: 0.8898 - val_loss: 0.0904 - val_accuracy: 0.9762\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 60s 2s/step - loss: 0.2647 - accuracy: 0.9145 - val_loss: 0.0807 - val_accuracy: 0.9881\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 61s 2s/step - loss: 0.2184 - accuracy: 0.9295 - val_loss: 0.0662 - val_accuracy: 0.9762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a02221450>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    }
  ]
}